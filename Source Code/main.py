# -*- coding: utf-8 -*-
"""test.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15Ey0phdJupxcpiqZPxfLAdOatlv-7IMd

### Based on the paper ***<u>Performance Evaluation of Machine Learning Methods for Breast Cancer Prediction.</u>***

#### This paper uses five Algorithms.
#### Namely: 
#### 1. Support Vector Machine
#### 2. Logistic Regression
#### 3. Random Forest
#### 4. Neural network
#### 5. Decision Tree

## Importing package
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd 
import numpy as np 
import matplotlib.pyplot as plt
import seaborn as sns

# Machine learning imports
from sklearn.model_selection import train_test_split
from sklearn.metrics import *
from sklearn.linear_model  import LogisticRegression
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier 
from keras.models import Sequential
from keras.layers import Dense
import warnings
warnings.filterwarnings('ignore')

# %matplotlib inline

"""## Loading Datasets"""

bccd = pd.read_csv('/Users/aneruthmohanasundaram/Documents/GitHub/Implementation-of-breast-cancer-prediction-using-machine-learning-techniques./Datasets/BCCD.csv')
wbcd = pd.read_csv('/Users/aneruthmohanasundaram/Documents/GitHub/Implementation-of-breast-cancer-prediction-using-machine-learning-techniques./Datasets/WBCD.csv')

"""# Machine Learning Model for BCCD dataset.

## Root map
## 1 --> Healthy
## 2 --> Patient
"""

# To check the head
bccd.head()

# To check the value counts of the classification
bccd['Classification'].value_counts()

# Renaming target values as 0 and 1 
bccd['Classification'] = bccd['Classification'].replace(1,0)
bccd['Classification'] = bccd['Classification'].replace(2,1)

"""## Analysing dataset"""

# To check correlation map
cor = bccd.corr()

# Plotting correlation map
plt.figure(figsize=(15,8))
sns.heatmap(cor, annot = True)

"""# Visualising our dataset"""

# Pairplot for our BCCD Dataset
sns.pairplot(data=bccd)

"""# Plotting the ditribution plot for our dataset"""

plt.figure(figsize=(15,6))
sns.distplot(bccd['Age'],kde=True)

plt.figure(figsize=(15,6))
sns.distplot(bccd['BMI'],kde=True)

plt.figure(figsize=(15,6))
sns.distplot(bccd['Glucose'],kde=True)

"""# ***Perform Machine Learning Stuff***

## Train Test and Split the dataset
"""

X = bccd.drop('Classification',axis=1)
y = bccd['Classification']

X_test,X_train,y_test,y_train = train_test_split(X,y,test_size=0.2,random_state=101)

"""## Logistic Regression"""

# from sklearn.linear_model import LogisticRegression
logisticreg = LogisticRegression(max_iter=10000)

# Training the model
logisticreg.fit(X_train,y_train)

# Predicting the model
predict1 = logisticreg.predict(X_test)

# Printing the Classification Report.
print('Classification Report for Logistic Regression:' + '\n\n' + classification_report(y_test,predict1))

"""## Support Vector Machine"""

svm = SVC()

# Training the model
svm.fit(X_train,y_train)

# Predicting the model
predict2 = svm.predict(X_test)

# Printing the Classification Report.
print('Classification Report for Support Vector Machine:' + '\n\n' + classification_report(y_test,predict2))

"""## Random Forest"""

rm = RandomForestClassifier(n_estimators=200)

# Training the model
rm.fit(X_train,y_train)

# Predicting the model
predict3 = rm.predict(X_test)

# Printing the Classification Report.
print('Classification Report for Random Forest:' + '\n\n' + classification_report(y_test,predict3))

"""## Decision Tree"""

dt = DecisionTreeClassifier()

# Training the model
dt.fit(X_train,y_train)

# Predicting the model
predict4 = dt.predict(X_test)

# Printing the Classification Report.
print('Classification Report for Decision Tree:' + '\n\n' + classification_report(y_test,predict4))

"""# Neural Network"""

neural = Sequential()
neural.add(Dense(12, input_dim=9, activation='relu'))
neural.add(Dense(8, activation='relu'))
neural.add(Dense(1, activation='sigmoid'))

neural.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

# Keras fit for BCCD dataset
BCCD_model.fit(X, y, epochs=150, batch_size=10)

# evaluate the keras model
_, accuracy = BCCD_model.evaluate(X, y)
print('Accuracy: %.2f' % (accuracy*100))

"""## Comapring the algorithms using ROC Curve Plot"""

classifiers = [logisticreg,dt,rm,svm]
ax = plt.gca()
for i in classifiers:
    plot_roc_curve(i, X_test, y_test, ax=ax)

# Plotting the accuracy score for all algorithms implemented
pred_list = [predict1,predict2,predict3,predict4]
predict_values = [(accuracy_score(y_test,i))*100 for i in pred_list]
predict_values.append((accuracy)*100)
plt.figure(figsize=(15,6))
plt.plot(['Logistic Regression','Support Vecotor Machine','Random Forest','ID3','Neural Network'],predict_values,marker='o')
plt.title('Accuracy Score for BCCD Dataset')
plt.xlabel('Algorithms Used')
plt.ylabel('Accuracy Score')

"""# WBCD Dataset 

## Dataset Keys 
## 2 --> benign (replacing it as 0)
## 4 --> malignant (replacing it as 1)
"""

# To print head of our dataset 
wbcd.head()

# Descirbing our dataset 
wbcd.describe()

# Classify our target class
wbcd.Class = wbcd.Class.replace(2,0)
wbcd.Class = wbcd.Class.replace(4,1)
wbcd.Class.value_counts()

# Checking row type of dataset
wbcd.dtypes

"""## One of our column has object where we need to change it t int64, because while training we might get some errors """

# Checking our shape value before eliminating ascii values 
wbcd.shape

# Checking our shape value after eliminating ascii values 
wbcd.shape

# Removing all ascii characters and checkign our dataset shape
wbcd = wbcd[~wbcd['Bare Nuclei'].isin(["?"])]

"""## Downcasting our string columns to integer or converting our object to integer values """

# Method 1
# pd.to_numeric(wbcd['Bare Nuclei'],downcast='integer') # We can see from above column that Bare Nuclei column is in Object type
# Method 2
wbcd = wbcd.astype(int)

# Dropping unwanted column 
wbcd = wbcd.drop('Sample code number',axis=1)

"""# Visulaising the dataset"""

# To check correlation map
corr = wbcd.corr()

# Plotting correlation map
plt.figure(figsize=(15,8))
sns.heatmap(corr, annot = True)

"""# ***Perform Machine Learning Stuff***

## Train Test and Split the dataset
"""

wbcd_X = wbcd.drop('Class',axis=1)
wbcd_y = wbcd['Class']

wbcd_X_test,wbcd_X_train,wbcd_y_test,wbcd_y_train = train_test_split(wbcd_X,wbcd_y,test_size=0.2,random_state=101)

"""# Decision Tree"""

# Training the model
dt.fit(wbcd_X_train,wbcd_y_train)

# Predicting the model
predict5 = dt.predict(wbcd_X_test)

# Printing the Classification Report.
print('Classification Report for Decision Tree:' + '\n\n' + classification_report(wbcd_y_test,predict5))

"""## Logistic Regression"""

# Training the model
logisticreg.fit(wbcd_X_train,wbcd_y_train)

# Predicting the model
predict6 = logisticreg.predict(wbcd_X_test)

# Printing the Classification Report.
print('Classification Report for Logistic Regression:' + '\n\n' + classification_report(wbcd_y_test,predict6))

"""## Random Forest"""

# Training the model
rm.fit(wbcd_X_train,wbcd_y_train)

# Predicting the model
predict7 = rm.predict(wbcd_X_test)

# Printing the Classification Report.
print('Classification Report for Random Forest:' + '\n\n' + classification_report(wbcd_y_test,predict7))

"""# Support Vector Machine"""

# Training the model
svm.fit(wbcd_X_train,wbcd_y_train)

# Predicting the model
predict8 = svm.predict(wbcd_X_test)

# Printing the Classification Report.
print('Classification Report for Support Vector Machine:' + '\n\n' + classification_report(wbcd_y_test,predict8))

## Comapring the algorithms using ROC Curve Plot
classifiers = [logisticreg,dt,rm,svm]
ax = plt.gca()
for i in classifiers:
    plot_roc_curve(i, wbcd_X_test, wbcd_y_test, ax=ax)

"""# Neural Network"""

wbcd_model = Sequential()
wbcd_model.add(Dense(12, input_dim=9, activation='relu'))
wbcd_model.add(Dense(8, activation='relu'))
wbcd_model.add(Dense(1, activation='sigmoid'))

wbcd_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

# Keras fit for WBCD dataset
wbcd_model.fit(wbcd_X, wbcd_y, epochs=150, batch_size=10)

# evaluate the keras model
_, wbcd_accuracy = wbcd_model.evaluate(wbcd_X, wbcd_y)
acc = (wbcd_accuracy*100)
print(f'Accuracy: {acc}')

# Plotting the accuracy score for all algorithms implemented
pred_list_1 = [predict5,predict6,predict7,predict8]
predict_values_1 = [(accuracy_score(wbcd_y_test,i))*100 for i in pred_list_1]
predict_values_1.append(acc)
plt.figure(figsize=(15,6))
plt.plot(['Logistic Regression','Support Vecotor Machine','Random Forest','ID3','Neural Network'],predict_values_1,marker='o')
plt.title('Accuracy Score for WBCD Dataset')
plt.xlabel('Algorithms Used')
plt.ylabel('Accuracy Score')

"""# Conclusion """

fig2 = plt.figure(figsize=(15,5))
ax = fig2.add_axes([0,0,1,1])
ax.plot(['Logistic Regression','Support Vecotor Machine','Random Forest','ID3','Neural Network'],predict_values,color='b' ,label='BCCD',marker='o')
ax.plot(['Logistic Regression','Support Vecotor Machine','Random Forest','ID3','Neural Network'],predict_values_1,color='r' ,label='WBCD',marker='o')
ax.legend(loc='best')

"""## From above graph we can conclude that Neural network prduces the best result for both of the datasets of 82% for BCCD dataset and 92% for WBCD dataset."""